{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2c6a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from util import resolve_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5106f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f07f20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH_DIAGNOSTICS = 'H:/Documents/NCATS/GBM/clinicalData/Updated_All_Dx_Data_For_Glioblastoma_Subjects_sent_to_Zhu_1-18-2022.xlsx - All_Diagnosis.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c59b21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dx_df(filepath: str=FILEPATH_DIAGNOSTICS) -> pd.DataFrame:\n",
    "    '''Does not exit pipe.'''\n",
    "\n",
    "    # Define available column types\n",
    "    column_types = {\n",
    "        # 'Row No': 'Int64',\n",
    "        'Subject': 'str',\n",
    "        'Date_of_death': 'str',  # to be parsed\n",
    "        'Race': 'string',  # cannot have `np.nan` as a category level\n",
    "        'Gender': 'string',  # cannot have `np.nan` as a category level\n",
    "        'Ethnic_group': 'string',  # cannot have `np.nan` as a category level\n",
    "        'Age at Time of Diagnosis': 'Int64',\n",
    "        'Date': 'str',  # to be parsed\n",
    "        'Diagnosis Type': 'string',  # cannot have `np.nan` as a category level\n",
    "        'ICD if Available': 'string',  # cannot have `np.nan` as a category level\n",
    "        'Main Diagnosis Text': 'str',\n",
    "        'Secondary Diagnosis Text': 'str',\n",
    "        # 'Review Note': 'str'  # all blanks\n",
    "    }\n",
    "\n",
    "    # Select desired columns\n",
    "    selected_columns = list(column_types.keys())\n",
    "\n",
    "    # Specify file-wide NA values\n",
    "    na_values = ['', 'NULL', 'NONE', 'Unknown']\n",
    "\n",
    "    # Import data\n",
    "    df = pd.read_csv(filepath, usecols=selected_columns,\n",
    "                     dtype=column_types, na_values=na_values)\n",
    "\n",
    "    # Parse datetimes\n",
    "    df['Date_of_death'] = pd.to_datetime(df['Date_of_death'], format='mixed')\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "\n",
    "    # In `Gender` column, correct misspelled values\n",
    "    gender_replacements = { 'M': 'Male' }\n",
    "    df['Gender'] = df['Gender'].replace(gender_replacements)\n",
    "\n",
    "    # In `Ethnic_group` column, fix misspelled and missing values\n",
    "    ethnic_replacements = {\n",
    "        'Not Hispanic or Lati': 'Not Hispanic or Latino',\n",
    "        'N': None,  # Is 'N' considered a missing value? BTRIS doesn't know, so better be safe\n",
    "        'Not Reported': None\n",
    "    }\n",
    "    df['Ethnic_group'] = df['Ethnic_group'].replace(ethnic_replacements)\n",
    "\n",
    "    # In the `...Diagnosis Text` columns (given `ICD if Available=='NULL'`), fix missing values\n",
    "    diagnoses_replacements = {\n",
    "        'UNKNOWN': None,\n",
    "        'UNKOWN': None,\n",
    "        'NOT SPECIFIED': None,\n",
    "        'DIAGNOSIS': None,  # (w/o ICD given,) this is not specific enough\n",
    "    }\n",
    "    df['Main Diagnosis Text'] = df['Main Diagnosis Text'].replace(diagnoses_replacements)\n",
    "    df['Secondary Diagnosis Text'] = df['Secondary Diagnosis Text'].replace(diagnoses_replacements)\n",
    "\n",
    "    # Cast nullable categorical columns into 'category' type, the non-nullable ones having already been cast\n",
    "    nullable_cols = ['Race', 'Gender', 'Ethnic_group',\n",
    "                    'Diagnosis Type', 'ICD if Available']\n",
    "    for col in nullable_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    '''This line is for `verify_consistent_demography()` in `multi_type_processing`.'''\n",
    "    # df.drop_duplicates(subset='Subject').to_pickle('../intermediates/dx_demo.pkl')\n",
    "\n",
    "    '''Note: No need to filter rows based on unique `Subject` values (the focus, at least in terms of comorbidities, is on ALL diagnoses).'''\n",
    "\n",
    "    print(f'Unique Subjects in this D.F.:\\t{df[\"Subject\"].unique().shape[0]}')  # TK Define this (1210) to be number of unique patients across all data types\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1927c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set text sizes for the two plots\n",
    "PLOT_SMALL_SIZE = 8\n",
    "PLOT_MEDIUM_SIZE = 10\n",
    "PLOT_BIGGER_SIZE = 12\n",
    "plt.rc('font', size=PLOT_SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=PLOT_SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=PLOT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=PLOT_SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=PLOT_SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=PLOT_SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=PLOT_BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bbded28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_conditions_barplot(df: pd.DataFrame, n_included: int=20,\n",
    "                            filepath_10: str='./lookups/Section111ValidICD10-Jan2023-DupFixed.xlsx',\n",
    "                            filepath_9: str='./lookups/Section111ValidICD9-Jan2023.xlsx'):\n",
    "    '''Simple barplot for frequency of co-morbidities. Exits pipeline because it's not modifying the data.'''\n",
    "\n",
    "    # Filter out (perhaps not all) rows recording procedures done\n",
    "    df = df[df['Diagnosis Type'] != 'Procedure']\n",
    "\n",
    "    # Sort bars by frequency of `ICD if Available` (imperfect)\n",
    "    conditions = df.groupby(by=['ICD if Available'], dropna=True).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "\n",
    "    # We are looking at CO-morbidities; filter out GARD==2491 (GBM) row\n",
    "    conditions = conditions[conditions['ICD if Available'] != '2491']\n",
    "\n",
    "    '''Collectively, the first four patterns match 1778 (out of 1778 total), unique (after `strip()` and pad) codes. TK cite all the links or download all this stuff or whatever'''\n",
    "    icd_9_pattern = r'^(?:\\d|E\\d?)\\d{2}\\.?\\d{0,2}$'\n",
    "    # Link: https://www.cms.gov/Medicare/Coding/ICD10/downloads/032310_ICD10_Slides.pdf\n",
    "    # Test: https://www.cms.gov/medicare/coordination-benefits-recovery-overview/icd-code-lists\n",
    "    # Note: Overlaps with `cpt_pattern`; Excludes 'V' (supplementary classification codes)\n",
    "    icd_10_cm_pattern = r'^[A-TV-Z]\\d[A-Z\\d](?:\\.?[A-Z\\d]{0,4})|U0(?:70|71|99)$'\n",
    "    # Link: https://www.cms.gov/Medicare/Coding/ICD10/downloads/032310_ICD10_Slides.pdf\n",
    "    # Test: https://www.cms.gov/medicare/coordination-benefits-recovery-overview/icd-code-lists\n",
    "    # Note: Overlaps with `hcpcs_sin_modifiers_pattern`\n",
    "    icd_9_proc_pattern = r'^\\d{1,2}(?:\\.\\d{1,2})?$'\n",
    "    # Test: http://www.icd9data.com/2012/Volume3/default.htm\n",
    "    icd_10_pcs_pattern = r'^[A-HJ-NP-Z\\d]{7}$'  # format-valid but maybe not semantic-valid\n",
    "    # Link: https://www.cms.gov/files/document/2022-official-icd-10-pcs-coding-guidelines-updated-december-1-2021.pdf\n",
    "    cpt_pattern = r'\\d{4}[FT\\d]'\n",
    "    # Link: https://en.wikipedia.org/wiki/Current_Procedural_Terminology#Types_of_code\n",
    "    # Note: Overlaps with `icd_9_pattern`\n",
    "    hcpcs_sin_modifiers_pattern = r'[A-CEGHJ-MP-V]\\d{4}'\n",
    "    # Link: https://www.aapc.com/codes/hcpcs-codes-range/\n",
    "    # Note: Pattern is not even specific to codes presented in [Link]. Overlaps with `icd_10_cm_pattern`\n",
    "\n",
    "    # Standardize code-strings by stripping whitespace, and, since some codes have removed prefixed '0's, left-padding with '0'\n",
    "    conditions['ICD if Available'] = conditions['ICD if Available'].astype(str).apply(lambda code: re.sub(r'^(\\d\\..*)$', r'0\\1', code.strip()))\n",
    "\n",
    "    # Filter out the rows which do not record diagnoses. (Note that there is some ambiguity between non-diagnoses/procedures vs. diagnoses, if going off of `ICD if Available` alone.)\n",
    "    conditions = conditions[conditions['ICD if Available'].str.match('|'.join([icd_9_pattern, icd_10_cm_pattern]))]\n",
    "\n",
    "    # Remove periods ('.') because that's how the codes are, in the lookup tables.\n",
    "    conditions['ICD if Available'] = conditions['ICD if Available'].str.replace('.', '')\n",
    "\n",
    "    # Speaking of lookup tables, load them (ICD9, ICD10)\n",
    "    icd10_df = pd.read_excel(filepath_10, header=0, usecols='A:B', index_col=0, dtype=str)\n",
    "    icd9_df = pd.read_excel(filepath_9, header=0, usecols='A:B', index_col=0, dtype=str)\n",
    "\n",
    "    # Concatenate (rbind) the two DataFrames, and...\n",
    "    lookup_df = pd.concat([icd10_df, icd9_df], axis='index')\n",
    "    # ...Combine their columns to create a single-column lookup DataFrame\n",
    "    lookup_df = lookup_df.iloc[:, 0].combine_first(lookup_df.iloc[:, 1])\n",
    "\n",
    "    def lookup_name(code: str) -> str:\n",
    "        '''Return the human-readable description of the diagnosis (based on the code). If a corresponding description doesn't exist for the code entered, it's probably a non-diagnosis/procedure code (e.g. a 'V'-prefixed ICD-9 code, mentioned above), and deemed unimportant.'''\n",
    "        try:\n",
    "            return lookup_df.loc[code]\n",
    "        except KeyError:\n",
    "            return ''\n",
    "\n",
    "    # Create new column of diagnoses names based on lookups\n",
    "    conditions['Dx Name based on ICD'] = conditions['ICD if Available'].astype(str).apply(lookup_name)\n",
    "\n",
    "    # Filter out blank (i.e. not found) diagnoses names\n",
    "    conditions = conditions[conditions['Dx Name based on ICD'] != '']\n",
    "\n",
    "    # Keep only the `n_included` most frequent diagnoses to display in the barplot\n",
    "    conditions = conditions.head(n_included)\n",
    "    plt.figure()\n",
    "    # Create the barplot\n",
    "    ax = sns.barplot(data=conditions, x='counts', y='Dx Name based on ICD')\n",
    "    plt.title(f'Frequency of top {n_included} Comorbidities')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Comorbidities')\n",
    "\n",
    "    # Loop through each bar\n",
    "    for p in ax.patches:\n",
    "        # Get the width of the bar (which is the count)\n",
    "        width = p.get_width()\n",
    "        # Annotate said bar with the count\n",
    "        ax.text(x=width + 0.1, y=p.get_y() + p.get_height() / 2,\n",
    "                    s=f'{int(width)}', ha='left', va='center')\n",
    "\n",
    "    # Automatically adjust the figure size\n",
    "    plt.tight_layout()\n",
    "    # Save this first figure as a PNG file\n",
    "    # plt.show()\n",
    "    plt.savefig('./plots/dx_hist_condtns.png')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d0abc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_gbm_dx(df: pd.DataFrame):\n",
    "    '''Keep only rows with first GBM diagnoses. Exits pipe because further processing is done elsewhere.'''\n",
    "\n",
    "    def keep_gbm_dx_rows_via_regex(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''Naive method: Identify, by eye, and mark all the GBM synonyms (synonyms/typos which were found comprehensively (in the xlsx)).'''\n",
    "\n",
    "        rows_GBM = df.copy()\n",
    "\n",
    "        '''Tests whether GBM diagnoses exclusion was too restrictive.'''\n",
    "        # # Read the file content\n",
    "        # with open(resolve_path('../intermediates/bob.txt'), 'r') as file:\n",
    "        #     content = file.read()\n",
    "        # # Split the content using the $ separator and store it in a list\n",
    "        # list_GBM = [re.escape(s) for s in content.split('$')]\n",
    "        # # Pattern it using OR logic\n",
    "        # match_pattern = '|'.join(list_GBM)\n",
    "        # # Match the pattern in the diagnoses\n",
    "        # rows_GBM['gbm_dx_marker'] = rows_GBM['Main Diagnosis Text'].str.match(match_pattern, case=False)\n",
    "\n",
    "        '''TK Link (Grade IV Astrocytoma == GBM): https://stanfordhealthcare.org/content/shc/en/medical-conditions/brain-and-nerves/astrocytoma/about-this-condition/stages.html/'''\n",
    "\n",
    "        # Matches 2879 (out of 19887) rows and 1025 (out of 1210) unique patients\n",
    "        # 1025 is to be expected because only 1033 is obtained after removing the generic 'neoplasm's and 'tumor's, without even excluding e.g. neuroblastomas and non-astrocytic gliomas.\n",
    "        contain_pattern = r'gi?li?o?(?:(?:bo?l?astr?|sarc)oma|matosis cerebri)|gbm|gmb|(?:anaplastic [a-z]*|GRADE IV |malignant )astrocyt?oma|(?:glioma )?(?:high grade|grade 3or 4)(?: glioma)?'\n",
    "        # TK include further justification (links) e.g for gliosarcoma and gliomatosis cerebri\n",
    "        # \"High grade\" (the same as \"grade 3or 4\") glioma included because (before 2021) GBM is grade 4 glioma (TK cite), and to include as many GBM diagnoses as possible.\n",
    "\n",
    "        rows_GBM['gbm_dx_marker'] = rows_GBM['Main Diagnosis Text'].str.contains(contain_pattern, case=False, regex=True)\n",
    "\n",
    "        # GBM == GARD2491 TK include other codes?\n",
    "        filter_result = rows_GBM[rows_GBM['gbm_dx_marker'] |\n",
    "                       (rows_GBM['ICD if Available'] == '2491')]\n",
    "\n",
    "        print(f'Total Rows in this D.F.:\\t{len(rows_GBM)}\\nRows recording GBM diagnosis:\\t{len(filter_result)}\\nSubjects with GBM diagnosis:\\t{len(filter_result.drop_duplicates(subset=\"Subject\"))}')\n",
    "\n",
    "        return filter_result\n",
    "\n",
    "    '''This line is not enough; there may be multiple (differently named) GBM diagnoses per patient'''\n",
    "    rows_GBM = keep_gbm_dx_rows_via_regex(df)\n",
    "\n",
    "    # Select only the useful columns\n",
    "    rows_GBM = rows_GBM[['Subject', 'Date_of_death', 'Date', 'Age at Time of Diagnosis']]\n",
    "\n",
    "    # For clarity, rename `Date` column\n",
    "    rows_GBM = rows_GBM.rename(columns={'Date': 'Date_of_Diagnosis'})\n",
    "\n",
    "    # De-space/Remove spaces in column names (so they won't get affected by `split(' ')` later on)\n",
    "    rows_GBM = rows_GBM.rename(\n",
    "        columns={col: col.replace(' ', '_') for col in rows_GBM.columns})\n",
    "\n",
    "    # Sort by date (ascending), so earliest GBM diagnosis date comes first\n",
    "    rows_GBM = rows_GBM.sort_values(by='Date_of_Diagnosis', ascending=True)\n",
    "\n",
    "    # Keep first occurrences of duplicated (by `Subject`) rows\n",
    "    rows_GBM = rows_GBM.drop_duplicates(subset='Subject', keep='first')\n",
    "\n",
    "    # Set index to `Subject` ID, to concatenate with similar DataFrames later\n",
    "    rows_GBM = rows_GBM.set_index('Subject', drop=True)\n",
    "\n",
    "    # Serialize the DataFrame\n",
    "    rows_GBM.to_pickle('./results/only_GBM_dx_dates.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "527a3e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Subjects in this D.F.:\t1210\n",
      "Percent of total right-censored:\t16.69%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19887 entries, 0 to 19886\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Subject                   19887 non-null  object        \n",
      " 1   Date_of_death             16529 non-null  datetime64[ns]\n",
      " 2   Race                      19599 non-null  category      \n",
      " 3   Gender                    19887 non-null  category      \n",
      " 4   Ethnic_group              19722 non-null  category      \n",
      " 5   Age at Time of Diagnosis  19887 non-null  Int64         \n",
      " 6   Date                      19887 non-null  datetime64[ns]\n",
      " 7   Diagnosis Type            19887 non-null  category      \n",
      " 8   ICD if Available          15220 non-null  category      \n",
      " 9   Main Diagnosis Text       18570 non-null  object        \n",
      " 10  Secondary Diagnosis Text  18444 non-null  object        \n",
      "dtypes: Int64(1), category(5), datetime64[ns](2), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_dx_df()\n",
    "print(f'Percent of total right-censored:\\t{df.drop_duplicates(subset=\"Subject\")[\"Date_of_death\"].isna().sum()/len(df.drop_duplicates(subset=\"Subject\")[\"Date_of_death\"]) * 100:.2f}%')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ad34002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Subjects in this D.F.:\t1210\n",
      "Total Rows in this D.F.:\t19887\n",
      "Rows recording GBM diagnosis:\t2879\n",
      "Subjects with GBM diagnosis:\t1025\n"
     ]
    }
   ],
   "source": [
    "#Standard pipeline (preprocess %>% deduplicate)\n",
    "deduplicate_gbm_dx(preprocess_dx_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efb3efee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualization pipline (preprocess %>% visualize)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m visualize_conditions_barplot(df)\n",
      "Cell \u001b[1;32mIn[45], line 7\u001b[0m, in \u001b[0;36mvisualize_conditions_barplot\u001b[1;34m(df, n_included, filepath_10, filepath_9)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Simple barplot for frequency of co-morbidities. Exits pipeline because it's not modifying the data.'''\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Filter out (perhaps not all) rows recording procedures done\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagnosis Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcedure\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Sort bars by frequency of `ICD if Available` (imperfect)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m conditions \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mICD if Available\u001b[39m\u001b[38;5;124m'\u001b[39m], dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Visualization pipline (preprocess %>% visualize)\n",
    "visualize_conditions_barplot(preprocess_dx_df())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
